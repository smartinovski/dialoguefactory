{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1099b93",
   "metadata": {},
   "source": [
    "# Introduction to DialogueFactory\n",
    "## Generating a dialogue\n",
    "\n",
    "This notebook demonstrates how to generate new dialogues and evaluate them using your own policy. We create a random dialogue in the \"easy\" environment and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846af0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dialoguefactory import DialogueGenerator\n",
    "import dialoguefactory.environments.easy as easy_env\n",
    "\n",
    "home_directory = os.path.expanduser('~')\n",
    "\n",
    "error_path = os.path.join(home_directory, 'dialoguefactory_logs', 'error.log')\n",
    "context_path = os.path.join(home_directory, 'dialoguefactory_logs', 'context.log')\n",
    "os.makedirs(os.path.dirname(error_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(context_path), exist_ok=True)\n",
    "\n",
    "\n",
    "easy_world = easy_env.build_world()\n",
    "generator = DialogueGenerator(easy_world, error_path, context_path)\n",
    "dialogue = generator.generate_dialogue()\n",
    "\n",
    "dialogue.run()\n",
    "print (\"The utterances:\")\n",
    "for utter in dialogue.utterances:\n",
    "    print (utter.to_string())\n",
    "    \n",
    "evaluated_dia = dialogue.evaluate_goal()\n",
    "if evaluated_dia == 1:\n",
    "    print (\"Success\")\n",
    "elif evaluated_dia == 0:\n",
    "    print (\"In progress\")\n",
    "else:\n",
    "    print (\"Failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be506e",
   "metadata": {},
   "source": [
    "As you can see, the dialogue consists of the user issuing a request to an agent. The agent's goal is to fulfill the user's request.\n",
    "\n",
    "The dialogue's goal is success because we use an Oracle agent's policy. Now, let us replace it with a dummy policy. \n",
    "\n",
    "The policies must have an execute function that returns the next agent's response. The get_goal function returns the agent's goal. We use the get_goal function from the oracle's policy as the dialogue's goal. For the machine learning policy, this function should return None. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dialoguefactory.language.components as lc\n",
    "import dialoguefactory.language.sentences as sentences\n",
    "from dialoguefactory.policies.base_policies import Policy\n",
    "\n",
    "class DummyPolicy(Policy):\n",
    "    \"\"\" We use this class to show an example of how to build a policy.\n",
    "        This policy has no logic implemented, just outputs the following sentence on each dialogue step:\n",
    "            <player> says: <player> saw <num> unseen sentences.\n",
    "    \"\"\"\n",
    "    def __init__(self, player, dialogue=None):\n",
    "        self.player = player\n",
    "        self.dialogue = dialogue\n",
    "        self.last_seen_cid = 0\n",
    "\n",
    "    def execute(self, include_goal=False, **params):\n",
    "        \"\"\" Runs the policy. It returns the next agent's response \"\"\"\n",
    "        steps = self.get_steps(**params)\n",
    "        if include_goal:\n",
    "            return steps, self.get_goal()\n",
    "\n",
    "        return steps\n",
    "    \n",
    "    def get_steps(self, **params):\n",
    "        \"\"\" Returns the next agent's response. Assigns the trusted_source flag to False since\n",
    "            the DummyPolicy is not a reliable source.\n",
    "        \"\"\"\n",
    "        num_unseen = len(self.dialogue.dia_generator.context)-self.last_seen_cid\n",
    "        example = sentences.say(self.player,\n",
    "                                None,\n",
    "                                \"says\",\n",
    "                                sentences.see(self.player, None, \"saw\", [str(num_unseen), 'unseen', 'sentences'] ),\n",
    "                                speaker=self.player)\n",
    "        \n",
    "        example.trusted_source = False\n",
    "        self.last_seen_cid = len(self.dialogue.dia_generator.context)\n",
    "        \n",
    "        return example\n",
    "    \n",
    "    def get_goal(self, **params):\n",
    "        \"\"\" Returns the goal of the policy \"\"\"\n",
    "        return None\n",
    "    \n",
    "    def save_state(self):\n",
    "        \"\"\" Saves the state that changes over time. This is useful in case you want to save the simulation at some time point.\n",
    "            For example if you had already evaluated some of the dialogues the state\n",
    "            of your policy as well. With save and recover state re-evaluation will be possible.\n",
    "        \"\"\"\n",
    "        parent_state = super().save_state()\n",
    "       \n",
    "        return (parent_state, self.last_seen_cid)\n",
    "        \n",
    "    def recover_state(self, state):\n",
    "        \"\"\" Recovers the saved state \"\"\"\n",
    "        parent_state, last_seen_cid = state\n",
    "        super().recover_state(parent_state)\n",
    "        self.last_seen_cid = last_seen_cid\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d2d1b",
   "metadata": {},
   "source": [
    "## Evaluating and submitting your solution\n",
    "\n",
    "We introduced a \"hard\" environment to test how well the agent generalizes. We connect the \"easy\" and \"hard\" environments with locked doors, preserving continuity and making the simulation more realistic. During the test phase, we unlock the doors between the two environments.\n",
    "\n",
    "In the example below, we evaluate our DummyPolicy on 100 samples. Please evaluate your model and report the metrics on 200.000 dialogues in which the agent participates. We have additional requirements that we explain in the Challenge subsection of our [paper](https://rgdoi.net/10.13140/RG.2.2.17884.19846). An example of evaluation can be seen in the [baseline](baseline.ipynb) notebook.\n",
    "\n",
    "When generating and evaluating the dialogues, the context can quickly grow and fill up the RAM. For this reason, we have developed an option to flush the dialogue generator. Flushing will save the context string sentences in the \"~/dialoguefactory_logs/context.log\" file. Flushing the generator does not lose any state because the knowledge base keeps all the information. The parameter that controls the flushing is called flush_after in the generate_and_eval function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc007b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dialoguefactory.environments.hard as hard_env\n",
    "from dialoguefactory.trainers.evaluation import generate_and_eval, pretty_print_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f137f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_world = hard_env.build_world()\n",
    "hard_env.merge_worlds(generator, hard_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_policy = DummyPolicy(easy_world.player)\n",
    "num_test_samples = 100\n",
    "dias, individual_accuracies, total_accuracy, total_num_dias = generate_and_eval (generator, None, num_test_samples, \n",
    "                                                                                 dummy_policy, flush_after=100, notebook_run=True)\n",
    "    \n",
    "pretty_print_eval(\"Example\", individual_accuracies, total_accuracy, num_test_samples, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21e891",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "For the same reason as flushing, dialogues by default, are not saved during evaluation by default. So, the *dias* variable in the cell above is empty. To debug the dialogues, please use the parameter *return_dias* set to True in the generate_and_eval function.\n",
    "\n",
    "If an error occurs during the dialogue run, it is saved in the \"~/dialoguefactory_logs/error.log\" file.\n",
    "\n",
    "If you want the dialogues and the generator to remain unchanged after evaluation, set the parameter *forgetful* to True. This is useful if you want to re-evaluate the same dialogues without changing the state of the generator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
